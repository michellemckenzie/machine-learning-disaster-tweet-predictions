{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECS 171 Team Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.9/site-packages (3.6.5)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: textblob in /opt/anaconda3/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/anaconda3/lib/python3.9/site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.9/site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install textblob\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description: Using NLT package to lemmatize words using POS (Parts of Speech) tagging because NLT POS default POS is noun, but want to take into account adjectives, verbs, and adverbs as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sofia/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# NLP Packages\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob \n",
    "from textblob import Word\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import WhitespaceTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sofia/dataclean.py:124: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data.text = data.text.str.replace('\\d+', '') #remove numbers\n",
      "/Users/sofia/dataclean.py:134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'][sentence] = re.sub(r\"http\\S+\", \"\", data['text'][sentence])\n",
      "/Users/sofia/dataclean.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'][sentence] = data['text'][sentence].translate(str.maketrans('', '', string.punctuation))\n"
     ]
    }
   ],
   "source": [
    "from dataclean import process_data\n",
    "\n",
    "train_df=process_data('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>our deed be reason of earthquake may allah for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>all resident ask to shelter in place be be not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nan</td>\n",
       "      <td>people receive wildfire evacuation order in ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan</td>\n",
       "      <td>just get sent photo from ruby alaska as smoke ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nan</td>\n",
       "      <td>rockyfire update california hwy close in both ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nan</td>\n",
       "      <td>flood disaster heavy rain cause flash flooding...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword                                               text  target\n",
       "0     nan  our deed be reason of earthquake may allah for...       1\n",
       "1     nan              forest fire near la ronge sask canada       1\n",
       "2     nan  all resident ask to shelter in place be be not...       1\n",
       "3     nan  people receive wildfire evacuation order in ca...       1\n",
       "4     nan  just get sent photo from ruby alaska as smoke ...       1\n",
       "5     nan  rockyfire update california hwy close in both ...       1\n",
       "6     nan  flood disaster heavy rain cause flash flooding...       1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "def pos_tagger(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "\n",
    "def lemmatize_text(texts):\n",
    "    \n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(texts))  \n",
    "    tagged_wordnet = map(lambda x: (x[0], pos_tagger(x[1])), tagged)\n",
    "    new_lemmatized_text = []\n",
    "    \n",
    "    for word, tag in tagged_wordnet:\n",
    "        if tag is None:\n",
    "            new_lemmatized_text.append(word)\n",
    "        else:        \n",
    "            new_lemmatized_text.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(new_lemmatized_text)\n",
    "    \n",
    "\n",
    "train_df['text'] = train_df['text'].apply(lambda x: lemmatize_text(x))\n",
    "\n",
    "train_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99a2a11adcd7e17f2c6b1516fc56b9d79687bb9cc8c5662ef03e641805a7bd23"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
